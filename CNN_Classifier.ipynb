{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNDL_project1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FyRj--w6YiuE",
        "K7J9QL3KZOYJ",
        "7R19VfZvKWFK",
        "L8u7ehgjqz8h",
        "Y01RGNqsp1RE",
        "uLX-zwCJqW30",
        "XPgw0WybHGbK",
        "CQvA8gsV8jsS"
      ],
      "toc_visible": true,
      "mount_file_id": "1Kim19eFE4a2jjSL-sLmJTzHpJ-l_38cY",
      "authorship_tag": "ABX9TyPPSJ+WfHCpbsFpIGb84t4w"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PJhyAKPIQ-xE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c59f8c8d-0913-4d0b-d1d6-4e4a58d7db16"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import os\n",
        "import cv2 \n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "from skimage.transform import rotate, AffineTransform\n",
        "from skimage.util import random_noise\n",
        "import copy\n",
        "\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras import backend as k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRj--w6YiuE",
        "colab_type": "text"
      },
      "source": [
        "## Functrion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AJCe_MbTul2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def progress_bar(count, total):\n",
        "    bar_len = 60\n",
        "    filled_len = int(round(bar_len * count / float(total)))\n",
        "    percents = round(100.0 * count / float(total), 1)\n",
        "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
        "    sys.stdout.write('\\r')\n",
        "    # the exact output you're looking for:\n",
        "    sys.stdout.write(\"[%-20s] %d%%\" % (bar, percents))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def plot_loss_accuracy(history,what_to_plot):\n",
        "  figure(num=None, figsize=(8,8), dpi=80, facecolor='w', edgecolor='k')\n",
        "  plt.plot(history[what_to_plot])\n",
        "  plt.plot(history['val_'+what_to_plot])\n",
        "  plt.title(what_to_plot + \" plot per epochs\" )\n",
        "  plt.ylabel(what_to_plot)\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train_data', 'validation_data'], loc='center right')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm,class_names, title='Confusion matrix', cmap='viridis'):\n",
        "  \n",
        "    figure(num=None, figsize=(12,12), dpi=80, facecolor='w', edgecolor='k')\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "           plt.text(j, i, cm[i,j],ha=\"center\", va=\"center\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "def generate_random_numbers(range_, number):\n",
        "  randomlist = []\n",
        "  for i in range(number):\n",
        "    n = random.randint(range_[0], range_[1])\n",
        "    randomlist.append(n)\n",
        "  return randomlist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7J9QL3KZOYJ",
        "colab_type": "text"
      },
      "source": [
        "## data prepration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdU4Hq9mLNRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height = 35\n",
        "width = 35\n",
        "channels = 3\n",
        "num_classes = 43\n",
        "n_inputs = height * width * channels\n",
        "\n",
        "dataset_path = \"/content/drive/My Drive/german_trafficsign_dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u20NuwCoKRml",
        "colab_type": "text"
      },
      "source": [
        "### train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYLG379hDYxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f85c0f51-970a-4d94-e578-8497bdd5f435"
      },
      "source": [
        "train_data_=[]\n",
        "train_labels_=[]\n",
        "\n",
        "for i in range(num_classes) :\n",
        "  path = dataset_path + \"Train/\" + str(i)\n",
        "  class_data_names = os.listdir(path)\n",
        "  \n",
        "  print(\"\\n class: \",i)\n",
        "  print(\"number of class data: \",len(class_data_names))\n",
        "\n",
        "  for j in range(len(class_data_names)):\n",
        "    if(j%100 == 0):\n",
        "      progress_bar(j,len(class_data_names))\n",
        "    try:\n",
        "      # name = class_data_names[j]\n",
        "      # path_to_image = path + \"/\" + name\n",
        "      # image = cv2.imread(path_to_image)\n",
        "      # image = cv2.resize(image, (height, width))\n",
        "      # train_data_.append(np.array(image))\n",
        "      train_labels_.append(i)\n",
        "      # cv2_imshow(image)\n",
        "    except AttributeError:\n",
        "      print(\" \")\n",
        "# np.save(\"train_data\",train_data_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " class:  0\n",
            "number of class data:  210\n",
            "[=========================================================---] 95%\n",
            " class:  1\n",
            "number of class data:  2220\n",
            "[===========================================================-] 99%\n",
            " class:  2\n",
            "number of class data:  2250\n",
            "[===========================================================-] 97%\n",
            " class:  3\n",
            "number of class data:  1410\n",
            "[============================================================] 99%\n",
            " class:  4\n",
            "number of class data:  1980\n",
            "[==========================================================--] 96%\n",
            " class:  5\n",
            "number of class data:  1860\n",
            "[==========================================================--] 96%\n",
            " class:  6\n",
            "number of class data:  420\n",
            "[=========================================================---] 95%\n",
            " class:  7\n",
            "number of class data:  1440\n",
            "[==========================================================--] 97%\n",
            " class:  8\n",
            "number of class data:  1410\n",
            "[============================================================] 99%\n",
            " class:  9\n",
            "number of class data:  1470\n",
            "[=========================================================---] 95%\n",
            " class:  10\n",
            "number of class data:  2010\n",
            "[============================================================] 99%\n",
            " class:  11\n",
            "number of class data:  1320\n",
            "[===========================================================-] 98%\n",
            " class:  12\n",
            "number of class data:  2100\n",
            "[=========================================================---] 95%\n",
            " class:  13\n",
            "number of class data:  2160\n",
            "[==========================================================--] 97%\n",
            " class:  14\n",
            "number of class data:  780\n",
            "[======================================================------] 89%\n",
            " class:  15\n",
            "number of class data:  630\n",
            "[=========================================================---] 95%\n",
            " class:  16\n",
            "number of class data:  420\n",
            "[=========================================================---] 95%\n",
            " class:  17\n",
            "number of class data:  1110\n",
            "[===========================================================-] 99%\n",
            " class:  18\n",
            "number of class data:  1200\n",
            "[=======================================================-----] 91%\n",
            " class:  19\n",
            "number of class data:  210\n",
            "[=========================================================---] 95%\n",
            " class:  20\n",
            "number of class data:  360\n",
            "[==================================================----------] 83%\n",
            " class:  21\n",
            "number of class data:  330\n",
            "[=======================================================-----] 90%\n",
            " class:  22\n",
            "number of class data:  390\n",
            "[==============================================--------------] 76%\n",
            " class:  23\n",
            "number of class data:  510\n",
            "[===========================================================-] 98%\n",
            " class:  24\n",
            "number of class data:  270\n",
            "[============================================----------------] 74%\n",
            " class:  25\n",
            "number of class data:  1500\n",
            "[========================================================----] 93%\n",
            " class:  26\n",
            "number of class data:  600\n",
            "[==================================================----------] 83%\n",
            " class:  27\n",
            "number of class data:  240\n",
            "[==================================================----------] 83%\n",
            " class:  28\n",
            "number of class data:  540\n",
            "[========================================================----] 92%\n",
            " class:  29\n",
            "number of class data:  270\n",
            "[============================================----------------] 74%\n",
            " class:  30\n",
            "number of class data:  450\n",
            "[=====================================================-------] 88%\n",
            " class:  31\n",
            "number of class data:  780\n",
            "[======================================================------] 89%\n",
            " class:  32\n",
            "number of class data:  240\n",
            "[==================================================----------] 83%\n",
            " class:  33\n",
            "number of class data:  689\n",
            "[====================================================--------] 87%\n",
            " class:  34\n",
            "number of class data:  420\n",
            "[=========================================================---] 95%\n",
            " class:  35\n",
            "number of class data:  1200\n",
            "[=======================================================-----] 91%\n",
            " class:  36\n",
            "number of class data:  390\n",
            "[==============================================--------------] 76%\n",
            " class:  37\n",
            "number of class data:  210\n",
            "[=========================================================---] 95%\n",
            " class:  38\n",
            "number of class data:  2070\n",
            "[==========================================================--] 96%\n",
            " class:  39\n",
            "number of class data:  300\n",
            "[========================================--------------------] 66%\n",
            " class:  40\n",
            "number of class data:  360\n",
            "[==================================================----------] 83%\n",
            " class:  41\n",
            "number of class data:  240\n",
            "[==================================================----------] 83%\n",
            " class:  42\n",
            "number of class data:  240\n",
            "[==================================================----------] 83%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-Jcu6Xxufb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load saved file because the above code takes to much to run in google colab\n",
        "train_data_ = np.load(\"/content/drive/My Drive/german_trafficsign_dataset/train_data.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r0uHeaxu3ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexes = np.arange(len(train_labels_))\n",
        "np.random.seed(85)\n",
        "np.random.shuffle(indexes)\n",
        "\n",
        "train_data = np.array(train_data_)\n",
        "train_labels = np.array(train_labels_)\n",
        "train_data = train_data[indexes]/255\n",
        "train_labels = train_labels[indexes]\n",
        "\n",
        "#prepare labels and make it one hot\n",
        "train_labels_hw2_extra = copy.deepcopy(train_labels)\n",
        "train_labels = to_categorical(train_labels,num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R19VfZvKWFK",
        "colab_type": "text"
      },
      "source": [
        "### test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1uPJvl-KaMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_csv = pd.read_csv(\"/content/drive/My Drive/german_trafficsign_dataset/Test.csv\")\n",
        "test_data_paths = test_csv['Path'].values\n",
        "test_labels_ = test_csv['ClassId'].values\n",
        "\n",
        "# test_data_=[]\n",
        "# for i in range(len(test_data_paths)):\n",
        "#   print(i)\n",
        "#   if(i%100 == 0):\n",
        "#     progress_bar(i,len(test_data_paths))\n",
        "#   try:\n",
        "#     name = test_data_paths[i]\n",
        "#     path_to_image = dataset_path + name\n",
        "#     image = cv2.imread(path_to_image)\n",
        "#     image = cv2.resize(image, (height, width))\n",
        "#     test_data_.append(np.array(image))\n",
        "#   except AttributeError:\n",
        "#     print(\" \")\n",
        "# np.save(\"test_data\",test_data_)\n",
        "\n",
        "test_data_ = np.load(\"/content/drive/My Drive/german_trafficsign_dataset/test_data.npy\")\n",
        "test_data = test_data_/255\n",
        "\n",
        "test_labels = np.array(test_labels_)\n",
        "test_labels = to_categorical(test_labels, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8u7ehgjqz8h",
        "colab_type": "text"
      },
      "source": [
        "## data perpration better way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4EyPAmQrEtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height = 35\n",
        "width = 35\n",
        "channels = 3\n",
        "num_classes = 43\n",
        "n_inputs = height * width * channels\n",
        "\n",
        "dataset_path = \"/content/drive/My Drive/NNDL/german_trafficsign_dataset/\"\n",
        "test_csv = pd.read_csv(\"/content/drive/My Drive/NNDL/german_trafficsign_dataset/Test.csv\")\n",
        "\n",
        "train_labels_=[]\n",
        "num_train_data_per_class ={}\n",
        "for i in range(num_classes) :\n",
        "  path = dataset_path + \"Train/\" + str(i)\n",
        "  class_data_names = os.listdir(path)\n",
        "  num_train_data_per_class[i] = len(class_data_names)\n",
        "  for j in range(len(class_data_names)):\n",
        "      train_labels_.append(i)\n",
        "\n",
        "train_labels = to_categorical(train_labels_,num_classes)\n",
        "train_data_ = np.load(dataset_path + \"train_data.npy\")\n",
        "\n",
        "test_data_paths = test_csv['Path'].values\n",
        "test_labels_ = test_csv['ClassId'].values\n",
        "test_labels = np.array(test_labels_)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "test_data_ = np.load(dataset_path + \"test_data.npy\")\n",
        "test_data = test_data_/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mahZAnPuAFk5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aa87b23-b23a-4b86-eeb5-ce1f2b4258c4"
      },
      "source": [
        "train_data_.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39209, 35, 35, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I0NlGTEqKFu",
        "colab_type": "text"
      },
      "source": [
        "mini batch and validation split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRrKmVUB_P09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, validation_data, train_labels, validation_labels = train_test_split(train_data_, train_labels, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4UZHXqsq6cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "BATCH_SIZE = 32\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen = train_image_generator.flow(train_data, train_labels, batch_size=BATCH_SIZE)\n",
        "validation_data_gen = validation_image_generator.flow(validation_data, validation_labels, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sbwDBXYT4TC",
        "colab_type": "text"
      },
      "source": [
        "# Data Augmantaion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y01RGNqsp1RE",
        "colab_type": "text"
      },
      "source": [
        "## method1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFwcOTvxp-Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_train_image_generator = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "augmented_train_data_gen = augmented_train_image_generator.flow(train_data, train_labels, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLX-zwCJqW30",
        "colab_type": "text"
      },
      "source": [
        "## method2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yCr2ABXm_-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_transformed_image(image):\n",
        "  my_gen =  ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=35,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "  random_transform_params = my_gen.get_random_transform((35, 35, 3))\n",
        "  return my_gen.apply_transform(image, random_transform_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXXKNeuMBm3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_devided = {}\n",
        "for i in range(num_classes):\n",
        "  train_data_devided[i] = []\n",
        "for i in range(train_data.shape[0]):\n",
        "  train_data_devided[train_labels[i].argmax()].append(train_data[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paHMRKSetAOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_train_data = []\n",
        "augmented_train_labels = []\n",
        "\n",
        "for i in range(num_classes):\n",
        "  count_to_augment = 1000 - len(train_data_devided[i])\n",
        "  indexes = generate_random_numbers([0,len(train_data_devided[i])-1], count_to_augment)\n",
        "  for j in indexes:\n",
        "    augmented_train_data.append(get_random_transformed_image(train_data_devided[i][j]))\n",
        "    augmented_train_labels.append(to_categorical(i, num_classes))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdpO75GV84Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_and_original_train_data = np.concatenate((train_data,augmented_train_data), axis=0)\n",
        "augmented_and_original_train_labels = np.concatenate((train_labels,augmented_train_labels), axis=0)\n",
        "augmented_train_data_gen = train_image_generator.flow(augmented_and_original_train_data, augmented_and_original_train_labels, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pof-5aPAUTVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def h_flip(image):\n",
        "#   return np.array(tf.image.flip_left_right(image))\n",
        "\n",
        "# def v_flip(image):\n",
        "#   return np.array(tf.image.flip_up_down(image))\n",
        "\n",
        "# def center_crop(image):\n",
        "#   return np.array(tf.image.central_crop(image, central_fraction=0.5))\n",
        "\n",
        "# def random_transform_image(image, final_height, final_width):\n",
        "#   transformations = {'horizontal flip': h_flip, \n",
        "#                       'vertical flip': v_flip,\n",
        "#                      'center crop': center_crop}\n",
        "\n",
        "# data_generator = ImageDataGenerator(brightness_range=(0.1, 0.9))\n",
        "\n",
        "#   transformed_image = image\n",
        "#   transformation_count = random.randint(1, len(transformations)) \n",
        "#   for i in range(transformation_count):\n",
        "#       key = random.choice(list(transformations))\n",
        "#       transformed_image = transformations[key](transformed_image)\n",
        "\n",
        "#   return cv2.resize(transformed_image, (final_height, final_width))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPgw0WybHGbK",
        "colab_type": "text"
      },
      "source": [
        "# define model and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZFBDIkOZ8Hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "\n",
        "def build_model(batch_normalization):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=16, kernel_size=(4, 4), activation='relu', input_shape = (train_data_.shape[1:])))\n",
        "  if batch_normalization: model.add(BatchNormalization())\n",
        "  model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "  if batch_normalization: model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "  if batch_normalization: model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "  #Compilation of the model\n",
        "  model.compile(\n",
        "      loss='categorical_crossentropy', \n",
        "      optimizer='adam', \n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def step_decay(epoch):\n",
        "  initial_lrate = 0.001\n",
        "  drop = 0.5\n",
        "  epochs_drop = 10\n",
        "  lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "  return lrate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhxkZ_yUccsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"drop_out_relu_aug_method2\"\n",
        "model_path = \"/content/drive/My Drive/german_trafficsign_dataset/my_models/my_model_\"\n",
        "\n",
        "model = build_model(0)\n",
        "# model.load_weights(\"/content/drive/My Drive/german_trafficsign_dataset/my_models/my_model_drop_out_relu_with_augmnet_40.ckpt\")\n",
        "# model = load_model(\"/content/drive/My Drive/german_trafficsign_dataset/my_models_final/my_model_drop_out_relu_with_augmnet_method1_40_80.h5\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "lrate = keras.callbacks.LearningRateScheduler(step_decay, verbose=0)\n",
        "# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "check_point_save = ModelCheckpoint(filepath = model_path + model_name +\"_{epoch}\"+\".h5\",\n",
        "                                                 save_weights_only=False,\n",
        "                                                 verbose=1, period=10)\n",
        "\n",
        "history = model.fit(augmented_train_data_gen,\n",
        "                    epochs = 100,\n",
        "                    steps_per_epoch = augmented_and_original_train_data.shape[0]//BATCH_SIZE,\n",
        "                    validation_data = validation_data_gen,\n",
        "                    validation_steps = validation_data.shape[0] // BATCH_SIZE,\n",
        "                    callbacks = [lrate, check_point_save])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzp6dq0N7r9p",
        "colab_type": "text"
      },
      "source": [
        "save model and history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qphEZkUq26um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "model.save(\"/content/drive/My Drive/german_trafficsign_dataset/my_models_final/my_model_\" + model_name + \".h5\") \n",
        "\n",
        "my_dic = history.history\n",
        "zd = zip(*my_dic.values())\n",
        "with open(\"/content/drive/My Drive/german_trafficsign_dataset/my_models_final/history_\" + model_name + \".csv\", 'w') as file:\n",
        "    writer = csv.writer(file, delimiter=',')\n",
        "    writer.writerow(my_dic.keys())\n",
        "    writer.writerows(zd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQvA8gsV8jsS",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSbdjg5q1SGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_loss_accuracy(history.history, \"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLHiCKZe79tG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0216d5b0-907c-4173-ad41-478502d2e140"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data, test_labels, verbose=2)\n",
        "print(\"model accurracy : \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model accurracy :  0.9806017279624939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxTJE2XeTm82",
        "colab_type": "text"
      },
      "source": [
        "confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLN46rnO9RER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['20 km/h', '30 km/h', '50 km/h', '60 km/h', '70 km/h', '80 km/h', '80 km/h end', '100 km/h', '120 km/h', 'No overtaking',\n",
        "               'No overtaking for tracks', 'Crossroad with secondary way', 'Main road', 'Give way', 'Stop', 'Road up', 'Road up for track', 'Brock',\n",
        "               'Other dangerous', 'Turn left', 'Turn right', 'Winding road', 'Hollow road', 'Slippery road', 'Narrowing road', 'Roadwork', 'Traffic light',\n",
        "               'Pedestrian', 'Children', 'Bike', 'Snow', 'Deer', 'End of the limits', 'Only right', 'Only left', 'Only straight', 'Only straight and right', \n",
        "               'Only straight and left', 'Take right', 'Take left', 'Circle crossroad', 'End of overtaking limit', 'End of overtaking limit for track']\n",
        "\n",
        "predictions = model.predict(test_data)\n",
        "predicted_labels=[]\n",
        "for pred in predictions:\n",
        "  predicted_labels.append(np.argmax(pred))\n",
        "\n",
        "\n",
        "color_maps =['viridis',\n",
        "            'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds',\n",
        "            'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',\n",
        "            'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']\n",
        "\n",
        "cm = confusion_matrix(test_labels_, predicted_labels)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "plot_confusion_matrix(cm, class_names, cmap=color_maps[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLwbqHghFtan",
        "colab_type": "text"
      },
      "source": [
        "# Seperation Index Analyis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssAySJ7yHpCV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "c73e888e-1d9f-434b-be6d-206990109887"
      },
      "source": [
        "model = load_model(\"/content/drive/My Drive/german_trafficsign_dataset/my_models_final/my_model_drop_out_relu_batch_normal.h5\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 16)        784       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               295168    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 43)                11051     \n",
            "=================================================================\n",
            "Total params: 321,211\n",
            "Trainable params: 321,051\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlC1D9xuL5w2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list of output of model for each layer\n",
        "from keras.models import Model\n",
        "all_layers_output = []\n",
        "for i in range(len(model.layers)):\n",
        "  all_layers_output.append(Model(inputs = model.layers[0].input, outputs=model.layers[i].output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMz1T-3XSq1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IS_first_approch(layer_index):\n",
        "  output_of_layer_n = all_layers_output[layer_index].predict(train_data)\n",
        "  sum_correct = 0\n",
        "  for i in range(len(train_data)):\n",
        "    print(i)\n",
        "    temp_output = copy.deepcopy(output_of_layer_n)\n",
        "    temp_output = temp_output - temp_output[i]\n",
        "    temp_output = np.absolute(temp_output)\n",
        "\n",
        "    min_ = np.inf\n",
        "    for j in range(len(train_data)):\n",
        "      if j != i:\n",
        "        norm1 = np.sum(temp_output[j])\n",
        "        if norm1 < min_:\n",
        "          min_ = norm1\n",
        "          min_index = j\n",
        "\n",
        "    if np.argmax(train_labels[i]) == np.argmax(train_labels[min_index]):\n",
        "      sum_correct = sum_correct + 1\n",
        "    \n",
        "  return sum_correct/len(train_data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv8DVM2JlzB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IS_socond_faster_approch(layer_index):\n",
        "  print(layer_index)\n",
        "  output_of_layer_n = all_layers_output[layer_index].predict(train_data)\n",
        "  sum_correct = 0\n",
        "\n",
        "  centers = {}\n",
        "  centers_count = {}\n",
        "  for i in range(num_classes):\n",
        "    centers[i] = 0\n",
        "    centers_count[i] = 0\n",
        "\n",
        "  for i in range(len(train_data)):\n",
        "    centers[train_labels_hw2_extra[i]] = centers[train_labels_hw2_extra[i]] + output_of_layer_n[i]\n",
        "    centers_count[train_labels_hw2_extra[i]] = centers_count[train_labels_hw2_extra[i]] +1\n",
        "\n",
        "  for i in range(num_classes):\n",
        "    centers[i] = centers[i]/centers_count[i]\n",
        "\n",
        "\n",
        "  for i in range(len(train_data)):\n",
        "    min_ = np.inf\n",
        "    for j in range(num_classes):\n",
        "      norm1 = np.sum(np.absolute(output_of_layer_n[i] - centers[j]))\n",
        "      if norm1 < min_:\n",
        "        min_ = norm1\n",
        "        min_index = j\n",
        "    if train_labels_hw2_extra[i] == min_index:\n",
        "      sum_correct = sum_correct + 1\n",
        "  \n",
        "  return sum_correct/len(train_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B15MMP8dcWAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IS_of_all_layers = []\n",
        "for i in range(len(model.layers)):\n",
        "  IS = IS_socond_faster_approch(i)\n",
        "  print(IS)\n",
        "  IS_of_all_layers.append(IS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txOvU1GQomPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "2ee95902-ab78-40ab-c606-0eb36ea333fe"
      },
      "source": [
        "figure(num=None, figsize=(8,8), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.plot(IS_of_all_layers)\n",
        "plt.title( \" Seperation Index \" )\n",
        "plt.xlabel('layer')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}